% THIS DOCUMENT IS TAILORED TO REQUIREMENTS FOR SCIENTIFIC COMPUTING.  IT SHOULDN'T
% BE USED FOR NON-SCIENTIFIC COMPUTING PROJECTS
\documentclass[12pt]{article}




\usepackage{amsmath, mathtools}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{colortbl}
\usepackage{xr}
\usepackage{hyperref}
\usepackage{longtable}
\usepackage{xfrac}
\usepackage{tabularx}
\usepackage{float}
\usepackage{siunitx}
\usepackage{booktabs}
\usepackage{caption}
\usepackage{pdflscape}
\usepackage{afterpage}

%packages added by me: Fasil Cheema
\usepackage{mathtools}
\usepackage{bm}
\usepackage{esvect}
%\usepackage{biblatex}

\DeclareMathOperator*{\argminA}{arg\,min}

\usepackage[round]{natbib}
    \bibliographystyle{plainnat}
    \renewcommand{\bibsection}{\subsubsection*{References}}
%\usepackage{refcheck}

\hypersetup{
    bookmarks=true,         % show bookmarks bar?
      colorlinks=true,       % false: boxed links; true: colored links
    linkcolor=red,          % color of internal links (change box color with linkbordercolor)
    citecolor=green,        % color of links to bibliography
    filecolor=magenta,      % color of file links
    urlcolor=cyan           % color of external links
}

%\input{../Comments}
%\input{../Common}

% For easy change of table widths
\newcommand{\colZwidth}{1.0\textwidth}
\newcommand{\colAwidth}{0.13\textwidth}
\newcommand{\colBwidth}{0.82\textwidth}
\newcommand{\colCwidth}{0.1\textwidth}
\newcommand{\colDwidth}{0.05\textwidth}
\newcommand{\colEwidth}{0.8\textwidth}
\newcommand{\colFwidth}{0.17\textwidth}
\newcommand{\colGwidth}{0.5\textwidth}
\newcommand{\colHwidth}{0.28\textwidth}

% Used so that cross-references have a meaningful prefix
\newcounter{defnum} %Definition Number
\newcommand{\dthedefnum}{GD\thedefnum}
\newcommand{\dref}[1]{GD\ref{#1}}
\newcounter{datadefnum} %Datadefinition Number
\newcommand{\ddthedatadefnum}{DD\thedatadefnum}
\newcommand{\ddref}[1]{DD\ref{#1}}
\newcounter{theorynum} %Theory Number
\newcommand{\tthetheorynum}{TM\thetheorynum}
\newcommand{\tref}[1]{TM\ref{#1}}
\newcounter{tablenum} %Table Number
\newcommand{\tbthetablenum}{TB\thetablenum}
\newcommand{\tbref}[1]{TB\ref{#1}}
\newcounter{assumpnum} %Assumption Number
\newcommand{\atheassumpnum}{A\theassumpnum}
\newcommand{\aref}[1]{A\ref{#1}}
\newcounter{goalnum} %Goal Number
\newcommand{\gthegoalnum}{GS\thegoalnum}
\newcommand{\gsref}[1]{GS\ref{#1}}
\newcounter{instnum} %Instance Number
\newcommand{\itheinstnum}{IM\theinstnum}
\newcommand{\iref}[1]{IM\ref{#1}}
\newcounter{reqnum} %Requirement Number
\newcommand{\rthereqnum}{R\thereqnum}
\newcommand{\rref}[1]{R\ref{#1}}
\newcounter{nfrnum} %NFR Number
\newcommand{\rthenfrnum}{NFR\thenfrnum}
\newcommand{\nfrref}[1]{NFR\ref{#1}}
\newcounter{lcnum} %Likely change number
\newcommand{\lthelcnum}{LC\thelcnum}
\newcommand{\lcref}[1]{LC\ref{#1}}

\usepackage{fullpage}

\newcommand{\deftheory}[9][Not Applicable]
{
\newpage
\noindent \rule{\textwidth}{0.5mm}

\paragraph{RefName: } \textbf{#2} \phantomsection 
\label{#2}

\paragraph{Label:} #3

\noindent \rule{\textwidth}{0.5mm}

\paragraph{Equation:}

#4

\paragraph{Description:}

#5

\paragraph{Notes:}

#6

\paragraph{Source:}

#7

\paragraph{Ref.\ By:}

#8

\paragraph{Preconditions for \hyperref[#2]{#2}:}
\label{#2_precond}

#9

\paragraph{Derivation for \hyperref[#2]{#2}:}
\label{#2_deriv}

#1

\noindent \rule{\textwidth}{0.5mm}

}

\begin{document}

\title{Software Requirements Specification for \progname: subtitle describing software} 
\author{\authname}
\date{\today}
	
\maketitle

~\newpage

\pagenumbering{roman}

\tableofcontents

~\newpage

\section*{Revision History}

\begin{tabularx}{\textwidth}{p{3cm}p{2cm}X}
\toprule {\bf Date} & {\bf Version} & {\bf Notes}\\
\midrule
02/05/2024 & 1.0 & Initial Upload\\
\bottomrule
\end{tabularx}

~\\

~\newpage

\section{Reference Material}

This document is based off of a template of commonality analysis/SRS by Dr Spencer Smith \citep{Ssmith}.

\subsection{Table of Units}

Throughout this document there are no physical units. This is due to the abstract mathematical nature of the software. 

\subsection{Table of Symbols}

The table that follows summarizes the symbols used in this document along with
their units (not applicable in this document).  The choice of symbols was made to be consistent with convex optimization literature and with existing documentation for optimization libraries.  The symbols are listed in alphabetical order.

\renewcommand{\arraystretch}{1.2}
%\noindent \begin{tabularx}{1.0\textwidth}{l l X}
\noindent \begin{longtable*}{l l p{12cm}} \toprule
\textbf{symbol} & \textbf{unit} & \textbf{description}\\
\midrule 
$\mathbf{A}$ & \si[per-mode=symbol] {-} & $\mathbf{A}$ is the $n \times n$ matrix that is the leading term in the function (which can be expressed in the quadratic form) which we seek to minimize.
\\
$\vv{\bm{b}}$ & \si[per-mode=symbol] {-} & $\vv{\bm{b}}$ is the $n \times 1$ column vector that is the second term in the function (which is in the quadratic form) we are trying to minimize. 
\\ 
$c$ & \si[per-mode=symbol] {-} & $c$ is the constant (real number) that is the third term in the function (which can be in the quadratic form) we are trying to minimize.
\\
$f$ & \si[per-mode=symbol] {-} & $f$ is the function of interest which we are trying to minimize.  
\\
$n$ & \si[per-mode=symbol] {-} & $n$ is a natural number and is the dimensionality of our input variable $\vv{\bm{x}}$, and hence the dimensionality of our problem. 
\\
$\vv{\bm{x}}$ & \si[per-mode=symbol] {-} & $\vv{\bm{x}}$ is the $n \times 1$ column vector that is the input variable that goes into our function.
\\
$\vv{\bm{x^*}}$ & \si[per-mode=symbol] {-} & $\vv{\bm{x^*}}$ is the $n \times 1$ column vector that is optimal (value of $\vv{\bm{x}}$ that when input into our function results in a minimum value).
\\
$\vv{\bm{x_0}}$ & \si[per-mode=symbol] {-} & $\vv{\bm{x^*}}$ is the $n \times 1$ column vector that is the initial (value of $\vv{\bm{x}}$ that is input into our minimizer).
\\
\bottomrule
\end{longtable*}

\subsection{Abbreviations and Acronyms}

\renewcommand{\arraystretch}{1.2}
\begin{tabular}{l l} 
  \toprule		
  \textbf{symbol} & \textbf{description}\\
  \midrule 
  A & Assumption\\
  CO & Convex Optimization\\
  DD & Data Definition\\
  GD & General Definition\\
  GS & Goal Statement\\
  IM & Instance Model\\
  LC & Likely Change\\
  PD & Positive Definite (matrix)\\
  PS & Physical System Description\\
  PSD & Positive Semidefinite (matrix)\\
  R & Requirement\\
  SRS & Software Requirements Specification\\
  TM & Theoretical Model\\
  \bottomrule
\end{tabular}\\


\subsection{Mathematical Notation}
 In this section we will introduce some mathematical notation which will be seen throughout the project and corresponding documentation. Most of the notation seen in this section and throughout the documentation will be consistent with most texts in the field \citep{strang09}. Boldface uppercase letters will denote matrices as seen in most texts, for example: $\mathbf{M}$ is a matrix. Vectors will always be denoted in boldface, lowercase letters with an arrow above for instance: $\vv{\bm{x}}.$ When a vector or matrix has a superscript $T$, this denotes the transpose operation; where $\mathbf{M}$ is a $m \times n$ matrix and therefore $\mathbf{M}^T$ becomes a $n \times m$ matrix. We may also utilize the dot product which will be denoted as $\cdot$; and the dot product of two vectors would be denoted as: $\vv{\bm{x}} \cdot \vv{\bm{y}}$, given that these two vectors are the same shape. For more discussion on these operations and notation please see the relevant literature \citep{strang09}. The other set of notation which may be seen will be the standard notation for denoting sets, relations, notation of real analysis and convex optimization. This is standardized in math and is consistent throughout textbooks, see for more information \citep{Boyd2005ConvexO,Hnig1972RealA,Press2002NumericalRI}.



\newpage

\pagenumbering{arabic}

\iffalse 

\plt{This SRS template is based on \citet{SmithAndLai2005, SmithEtAl2007,
  SmithAndKoothoor2016}.  It will get you started.  You should not modify the
  section headings, without first discussing the change with the course
  instructor.  Modification means you are not following the template, which
  loses some of the advantage of a template, especially standardization.
  Although the bits shown below do not include type information, you may need to
  add this information for your problem.  If you are unsure, please can ask the
  instructor.}

\plt{Feel free to change the appearance of the report by modifying the LaTeX
  commands.}

\plt{This template document assumes that a single program is being documented.
  If you are documenting a family of models, you should start with a commonality
  analysis.  A separate template is provided for this.  For program
  families you should look at \cite{Smith2006, SmithMcCutchanAndCarette2017}.
  Single family member programs are often programs based on a single physical
  model.  General purpose tools are usually documented as a family.  Families of
  physical models also come up.}

\plt{The SRS is not generally written, or read, sequentially.  The SRS is a
  reference document.  It is generally read in an ad hoc order, as the need
  arises.  For writing an SRS, and for reading one for the first time, the
  suggested order of sections is:
\begin{itemize}
\item Goal Statement
\item Instance Models
\item Requirements
\item Introduction
\item Specific System Description
\end{itemize}
}

\plt{Guiding principles for the SRS document:
\begin{itemize}
\item Do not repeat the same information at the same abstraction level.  If
  information is repeated, the repetition should be at a different abstraction
  level.  For instance, there will be overlap between the scope section and the
  assumptions, but the scope section will not go into as much detail as the
  assumptions section.
\end{itemize}
}

\plt{The template description comments should be disabled before submitting this
  document for grading.}

\plt{You can borrow any wording from the text given in the template.  It is part
  of the template, and not considered an instance of academic integrity.  Of
  course, you need to cite the source of the template.}

\plt{When the documentation is done, it should be possible to trace back to the
  source of every piece of information.  Some information will come from
  external sources, like terminology.  Other information will be derived, like
  General Definitions.}

\plt{An SRS document should have the following qualities: unambiguous,
  consistent, complete, validatable, abstract and traceable.}

\plt{The overall goal of the SRS is that someone that meets the Characteristics
  of the Intended Reader (Section~\ref{sec_IntendedReader}) can learn,
  understand and verify the captured domain knowledge.  They should not have to
  trust the authors of the SRS on any statements.  They should be able to
  independently verify/derive every statement made.}

\fi 
\section{Introduction}
Function optimization is a critical task in many domains ranging from machine learning to finance. In many of these practical scenarios we are given a function that we seek to minimize or maximize and return an acceptable solution. More specifically when dealing with unconstrained optimization problems the setup is almost always identical; we are given the function we wish to minimize/maximize, we choose a particular optimizer, finally we input a choice of initial value and several hyperparameters relating to the optimizer such as the number of steps, the step size, the initial parameters of the optimizer to name a few. If given an optimization problem that has constraints the first objective is to first convert the problem into an unconstrained one. All our considerations will be assuming no constraints. For the task at hand we will focus specifically on function minimization. In machine learning the corresponding problem would be defining a loss function and then minimizing said loss function. In business the problem becomes defining a cost function in the business and minimizing the cost to maximize profits. Although different domains may have slightly different termiology the abstract problem they are trying to solve is the same.
\\

There are numerous resources to aid in solving problems of this nature, however in this project we would like to focus on a few such optimizers. We would like to develop a library of function minimizers including the David-Fletcher-Powell (DFP), Fletcher-Reeves Conjugate Gradient, and the Broyden-Fletcher-Goldfarb-Shanno (BFGS) algorithms. 
\\

In this document we would like to outline the Software Requirement Specification (SRS) for our project which is developing a family of optimizers to minimize functions. This section introduces the project, the purpose of this document, the scope of requirements, the characteristics of the intended reader, and the organization of the SRS document.

\plt{The introduction section is written to introduce the problem.  It starts
  general and focuses on the problem domain. The general advice is to start with
a paragraph or two that describes the problem, followed by a ``roadmap''
paragraph.  A roadmap orients the reader by telling them what sub-sections to
expect in the Introduction section.}

\subsection{Purpose of Document}

This document will describe a family of optimizers used for function optimization. This document is meant to act as a reference guide to users who wish to utilize the optimization library. This optimization library will contain several functions that will take a function and corresponding hyperparameters and output a potential solution. This document aims to communicate all necessary details for the design stage and try to communicate the developers' goals throughout this process. This document also acts as a guide to the developers of this document to bring our high level goals to reality and guide development. This document will contain all the major assumptions, goals, theory, and other high level abstractions in one place for users to read. To this end, this document is meant to be abstract and focuses on the high level ideas underpinning the project and not all the technical details required to actually solve the main problem. This is an initial step in the design of this project and will be heavily referenced in the future especially in the VnV plan (verification and validation).

  

\subsection{Scope of the Family} 
The scope of the problem starts off with function optimization. Given a mathematical function our goal is to optimize the function which may imply finding all global/local minima or maxima. In the real world function optimization problems may also come with constraints attached to the function, this adds another dimension of difficulty in finding acceptable solutions. the complexity of the problem is hence directly related to the possible functions that can be passed to the optimizer, the convexity (or lack thereof) of the function, the constraints attached to the function, and the choice of optimizer. Given a convex optimization function most optimizers are guaranteed to obtain the global minimum/maximum in a certain number of steps. Even though we may be granted full access to a well defined function obtaining the optimum value is still a computationally difficult task.
\\

We will limit ourselves to problems that are unconstrained. Also, instead of focusing on problems of minimization and maximization we will constrain the library to solve minimization problems specifically. Also to ensure the problem remains feasible we wish to limit the class of possible functions. We limit ourselves to the class of functions that can be expressed in quadratic form; that is quadratic, linear and constant functions. We will also assume these functions will be convex (this comes in later where we assume input matrices are positive semi-definite). Also functions will be described using matrices as we see later on. 
\\

Relatively recently there is huge growth in developing optimizers, therefore there is a plethora of optimization algorithms available. However, most algorithms fall into two main families: \textit{Quasi-Newton methods} and \textit{Conjugate-Gradient methods.} \textit{Quasi-Newton methods} are methods that are based on newton's method when trying to minimize/maximize functions. The basic iterative formula of Newton's method utilizes the Gradient and Hessian (multivariable generalizations of 1st and 2nd order derivatives) to update the search. In \textit{Quasi-Newton methods} we assume we do not have access to the Hessian so we approximate it, utilizing an initial choice of Hessian and updating according to hyperparameters of a particular algorithm. \textit{Conjugate-Gradient methods} on the other hand utilizes conjugate directions to find a minimum/maximum. For our particular case, as we will see, given a symmetric matrix $\mathbf{A}$ we compute conjugate directions with respect to this matrix. These methods utilize just the gradient of the function and conduct a one-dimensional sub-minimization routine. 
\\

Both families, generally all optimization problems, boil down to given initial conditions, a function, and necessary hyperparameters computing a search direction then updating and repeating this process until an acceptable solution is found. The `acceptability' of the solution, the search direction, and conducting updates are determined by the choice of family and moreso the particular algorithm. We can organize the optimizers by the style of choices made. As we discussed both families and their differences there are some key similarities. After obtaining a search direction update the iteration (this is the current iteration of the initial vector choice $\vv{\bm{x}}$) both families involve one-dimensional sub-minimization routines. 
\\

Clearly this problem domain is very general and abstract. To simplify the problem we apply several restrictions that keeps our problem feasible. We restrict the class of possible functions to simply those that can be expressed in the quadratic form this is our first assumption A\ref{assumption:convexity}. We also restrict the dimensionality of the input vector to be finite and more explicitly define the max dimension in A\ref{assumption:maxdim}. We also have an assumption, A\ref{assumption:quadratic}, that cater well to our \textit{Conjugate-Gradient methods} where we assume that the matrix $\mathbf{A}$ is postive semi-definite (PSD), which implies it is symmetric \citep{Boyd2005ConvexO}. This is key because as we stated earlier the nature of the optimum; whether or not there exists local minima/maxima is dependent on this assumption. By assuming the matrix is PSD we know we are dealing with a convex optimization problem and this ensures we will have a global optimum. Finally, we choose to focus on function minimization, this task can be easily extended to function maximization but for this project we will have this sole focus.


\plt{Modelling the real world requires simplification.  The full complexity of
  the actual physics, chemistry, biology is too much for existing models, and
  for existing computational solution techniques.  Rather than say what is in
  the scope, it is usually easier to say what is not.  You can think of it as
  the scope is initially everything, and then it is constrained to create the
  actual scope.  For instance, the problem can be restricted to 2 dimensions, or
  it can ignore the effect of temperature (or pressure) on the material
  properties, etc.}  

\plt{The scope section is related to the assumptions section
  (Section~\ref{sec_assumpt}).  However, the scope and the assumptions are not
  at the same level of abstraction.  The scope is at a high level.  The focus is
  on the ``big picture'' assumptions.  The assumptions section lists, and
  describes, all of the assumptions.}



\subsection{Characteristics of Intended Reader} \label{sec_IntendedReader}
The intended readers should have preliminary knowledge of function optimization. This would definitely be achieved if the individual has taken a course in convex optimization, numerical optimization, numerical methods, or discrete optimization. The reader should definitely have completed a high school mathematics curriculum and have a good grasp of preliminary mathematics taught in undergraduate degrees such as linear algebra and calculus. A reader should have knowledge on matrix operations, gradients, and Hessians.
\\

\subsection{Organization of Document}
This document adheres to the  Commonality Analysis Template which is related to the SRS template for the development of scientific computing software described by \citep{l}. This document will follow a top-down approach of going from high-level abstractions down to more specific details. This document contains the goals, assumptions, theory, necessary documentation for the software project. Note that although written with a particular flow of abstractions to instance models this document can be read ad-hoc for users who seek to utilize the software and readers can feel free to simply go to sections relevant to them. 
\\



\section{General System Description}
This section provides general information about the system.  It identifies the
interfaces between the system and its environment, describes the user
characteristics and lists the system constraints.
\\


\subsection{System Context}
The first context can be seen in Figure \ref{img:FigureSystemContext} where a user (can be a program interfacing with the library) uses the library to minimize a function with given parameters. In the figure arrows represent the flow of data when interacting with the library. The user through the programming interface will give the function in appropriate format along with the relevant parameters to the chosen minimizer in the library. This is represented by the arrow from user to the box. The arrow from the box to the user is then represented as the acceptable solution or whatever the final result of the minimizer is back to the user. 
\\


\begin{figure}[h!]
\begin{center}
 \includegraphics[width=0.9\textwidth]{Images/Fig1SystemContext.jpg}
\caption{System Context}
\label{img:FigureSystemContext}
\end{center}
\end{figure}

\plt{For each of the entities in the system context diagram its responsibilities
  should be listed.  Whenever possible the system should check for data quality,
  but for some cases the user will need to assume that responsibility.  The list
  of responsibilities should be about the inputs and outputs only, and they
  should be abstract.  Details should not be presented here.  However, the
  information should not be so abstract as to just say ``inputs'' and
  ``outputs''.  A summarizing phrase can be used to characterize the inputs.
  For instance, saying ``material properties'' provides some information, but it
  stays away from the detail of listing every required properties.}

\begin{itemize}
\item User Responsibilities:
\begin{itemize}
\item Ensure that the function they input can be expressed in quadratic form
\item Ensure the problem's dimensionality is consistent
\item Ensure the problem's dimensionality does not exceed the limitations of the library
\item Ensure that the problem is convex; $\mathbf{A}$ is PSD
\item Provide valid values of the initial value of $\vv{\bm{x}}$)
\item Provide valid values of hyperparameters for the algorithm they employ
\item Declare which minimizer they utilize from the library
\item Ensure the function library use complies with the user guide
\end{itemize}
\item \progname{Optimization Library} Responsibilities:
\begin{itemize}
\item Calculate the minimum value of a valid function if possible.
\item Update the values of the current iteration according to the specific algorithm
\item Determine the step size for the particular algorithm (if applicable for that algorithm)
\item Detect data type mismatch, such as a string of characters instead of a
  floating point number
\end{itemize}
\end{itemize}



\subsection{User Characteristics} \label{SecUserCharacteristics}
The user should be well acquainted with interacting with a program library. Since the project will be a library of functions the user should be able to know how to call a particular function and feed it input parameters. The user should also have knowledge of matrices and vectors and matrix operations such as transpose, matrix/vector multiplication etc. Knowledge of Linear Algebra of undergraduate level 2 is needed. The user should also understand the nature of the inputs and their affects on the result. For instance providing a PSD matrix can guarantee a correct result in some finite number of steps, whereas providing a function that is not convex and running a minimizer may not return an acceptable solution. Therefore knowledge of convex optimization at the undergraduate level is needed. 
\\



\subsection{System Constraints}
We constrain our family of minimization solvers to be restricted to 6 dimensions. This is due to the demanding computational costs of conducting matrix operations on high dimensional matrices.


\section{Specific System Description/ Commonalities}


This section first presents the problem description, which gives a high-level
view of the problem. This section contains the common assumptions, theories, definitions and instance models relevant to the family of solvers.



\subsection{Problem Description} \label{Sec_pd}
Function optimization is a problem that is found in a wide variety of fields. Minimization of a cost or loss function is a very common problem in business and machine learning to name a few examples. Therefore, it is imperative to have a set of efficient and correct algorithms to solve this task. 
 The common problem of our optimization library will be to minimize a given function. More specifically, given a function we wish to find an $n-$dimensional vector that is the minimum value of the provided function (subject to no constraints). This is known as an unconstrained function minimization problem.
 
\\




\subsubsection{Terminology and  Definitions}

This subsection provides a list of terms that are used in the subsequent
sections. This is to alleviate any confusion in proceeding sections where these terms will show up frequently.

\begin{itemize}

\item \textbf{Convex function:} is a function where the line between any 2 distinct points on the graph will lie above the graph.
\item \textbf{Quadratic Form:} is a transformation where given a matrix and a vector; the quadratic form is the transpose of the vector times the matrix times the vector. This returns a real number given that both the vector and the matrix have real entries and are of appropriate shape.
\item \textbf{Positive Semi-Definite (PSD) Matrix:} A matrix is PSD if it symmetric with real entries and if for any vector such that the quadratic form of this matrix and vector (this is a real number) is either positive or 0.
\item \textbf{Positive Definite (PD) Matrix:} A matrix is PD if the same conditions hold for PSD except if for any vector the real number derived from the quadratic form of the matrix and vector must strictly be positive.
\item  \textbf{Local Minimum:} A local minimum is a value of a function that is lesser than or equal to all other values of that function within a specified range (hence local). 
\item \textbf{Global Minimum:} A global minimum is a value of a function that is lesser than or equal to all other values of that function.
\item  \textbf{Local Minimum Point:} A local minimum point is a value such that when input into a function, the function returns a value that is lesser than or equal to all other values of that function within a specified range (hence local). 
\item \textbf{Global Minimum Point:} A global minimum point is a value such that when input into a function, the function returns a value that is that is lesser than or equal to all other values of that function.
\item \textbf{Search Direction:} At each iteration, a minimizer has a current input value and if it is not deemed to be a minimum point the minimizer computes a search direction which should be a vector that `points' to a point that outputs a function value smaller than the current iteration.  
\item \textbf{Step-Size:} After obtaining a search direction a step size is a real number which indicates the magnitude of how far along the search direction we should go to obtain the next iteration point.It is important to note that when told to use full-steps this indicates always using a step size of 1. 

\end{itemize}

\subsubsection{Physical System Description} \label{sec_phySystDescrip}
Given a function that can be expressed in the quadratic form. Assuming this function is also convex we wish to apply one of the family of minimizers to obtain a global minimum. The commonalities between all members of the family are conducting a line search via a search direction and a step size. Both the step size and the search direction are computed in a specific way by a particular algorithm.
\\

The main scenario includes the following elements:

\begin{itemize}

\item[PS1:] Step-Size: as defined prior and computed specifically via a particular algorithm

\item[PS2:] Search Direction: as defined prior and computed specifically via a particular algorithm

\item[PS3:] Function: the function we are trying to minimize

\item[PS4:] Initial guess: the first initial `guess' of the global minimum


\end{itemize}


% \begin{figure}[h!]
% \begin{center}
% %\rotatebox{-90}
% {
%  \includegraphics[width=0.5\textwidth]{<FigureName>}
% }
% \caption{\label{<Label>} <Caption>}
% \end{center}
% \end{figure}

\subsubsection{Goal Statements}
Given a function in an appropriate format, initial starting vector, and the corresponding initial parameters for the particular minimizer the goal statements are: 

\iffalse
\plt{The goal statements refine the ``Problem Description''
  (Section~\ref{Sec_pd}).  A goal is a functional objective the system under
  consideration should achieve. Goals provide criteria for sufficient
  completeness of a requirements specification and for requirements
  pertinence. Goals will be refined in Section “Instanced Models”
  (Section~\ref{sec_instance}). Large and complex goals should be decomposed
  into smaller sub-goals.  The goals are written abstractly, with a minimal
  amount of technical language.  They should be understandable by non-domain
  experts.}

\noindent Given the \plt{inputs}, the goal statements are:
\fi

\begin{itemize}

\item[GS\refstepcounter{goalnum}\thegoalnum \label{goal:G_min}:] Given the function, initial value, input parameters, and stopping conditions minimize the function and return the value for which the function reaches a minimum.

\end{itemize}

\subsection{Solution Characteristics Specification}
In this section, information regarding the solution domain of the system is stated. The common themes of the minimizers in the family of minimizers is stated. There are two main families of solvers the \textit{Quasi-Newton} and the \textit{Conjugate-Gradient} methods. Even though there are two families they follow a similar template. They both start off with a starting `guess' of the point that returns the minimum. They then use their own specific methodology to compute a search direction and a step size (if applicable). They then obtain a new `guess' of the minimum by adding the search direction times the step size to the initial guess. This process iterates until a minimum is reached or we have exceeded the maximum number of steps. Eitehr way a value is returned to the user. \textit{Conjugate-Gradient} methods utilize conjugate search directions in the computation of search direction step. \textit{Quasi-Newton} methods compute the search direction with information utilizing a term that is an approximation to the Hessian.  
\\

The instance models that govern the Optimization Library are presented in
Subsection~\ref{sec_instance}.  The information to understand the meaning of the
instance models and their derivation is also presented, so that the instance
models can be verified.


\subsubsection{Assumptions} \label{sec_assumpt}
This section states assumptions made in defining and setting up the problem. Assumptions are a refinement of the scope and are used when tackling GS\ref{goal:G_min}
\\

This section simplifies the original problem into a high level abstraction.
It helps in developing the theoretical model by filling in the missing information for main problem of function optimization.
In the following sections acronyms in the square brackets refer to the theoretical model [TM],
general definition [GD], data definition [DD], instance model [IM], or likely
change [LC], in which the respective assumption is used.

\begin{itemize}

\item[A\refstepcounter{assumpnum}\theassumpnum \label{assumption:convexity}:]
  The input function is convex.
\item[A\refstepcounter{assumpnum}\theassumpnum \label{assumption:quadratic}:]
  The input function can be expressed in the quadratic form.
\item[A\refstepcounter{assumpnum}\theassumpnum \label{assumption:maxdim}:]
  The dimensionality of the problem is finite and below the specified max dimension

\end{itemize}

\subsubsection{Theoretical Models}\label{sec_theoretical}
This section provides theoretical models relevant to the optimization library.


~\newline

\noindent
\deftheory
% #2 refname of theory
{TM:CON}
% #3 label
{Function Convexity}
% #4 equation
{
  $f(\lambda x_{1} + (1 - \lambda) x_{2}) \leq \lambda f(x_1) + (1-\lambda)f(x_2)$
}
% #5 description
{
  The above inequality is the definition of function convexity. For a convex function $f$, 2 points $x_1$ and $x_2$, and $0 \leq \lambda \leq 1$
}
% #6 Notes
{
None.
}
% #7 Source
{
  \url{https://en.wikipedia.org/wiki/Convex_function}
}
% #8 Referenced by
{
  GD\ref{gd:funcmin}
}
% #9 Preconditions
{
None
}
% #1 derivation - not applicable by default
{}



~\newline

\subsubsection{General Definitions}\label{sec:gd}



This section collects the general high-level ideas that will be used in building the
instance models.


~\newline

\noindent
\begin{minipage}{\textwidth}
\renewcommand*{\arraystretch}{1.5}
\begin{tabular}{| p{\colAwidth} | p{\colBwidth}|}
\hline
\rowcolor[gray]{0.9}
Number& GD\refstepcounter{defnum}\thedefnum \label{gd:funcmin}\\
\hline
Label &\bf Function Minimization \\
\hline
% Units&$MLt^{-3}T^0$\\
% \hline
SI Units&-\\
\hline
Equation&$ \argminA_{\vv{\bm{x}}\in \mathbb{R}^n} f(\vv{\bm{x}})$  \\
\hline
Description &
The standard statement of function minimization. Given a function $f$, we wish to find the value of $\vv{\bm{x}}$ that minimizes the function $f$.
\\
& For convex functions we are guaranteed to not have local minima only a global minimum. 
\\
\hline
  Source & \citep{Boyd2005ConvexO} \\
  \hline

\end{tabular}
\end{minipage}\\

\subsubsection*{Detailed derivation of simplified rate of change of temperature}

\plt{This may be necessary when the necessary information does not fit in the
  description field.}
\plt{Derivations are important for justifying a given GD.  You want it to be
  clear where the equation came from.}

\subsubsection{Data Definitions}\label{sec_datadef}

This section has data definitions used to build instance models for the optimization library.

~\newline

\noindent
\begin{minipage}{\textwidth}
\renewcommand*{\arraystretch}{1.5}
\begin{tabular}{| p{\colAwidth} | p{\colBwidth}|}
\hline
\rowcolor[gray]{0.9}
Number& DD\refstepcounter{datadefnum}\thedatadefnum \label{dd:DotProd}\\
\hline
Label& \bf Dot Product\\
\hline
Symbol &$\vv{\bm{x}} \mathbf{\cdot} \vv{\bm{y}}$\\
\hline
% Units& $Mt^{-3}$\\
% \hline
  SI Units & -\\
  \hline
  Equation&$\sum_{i=1}^{n}x_{i}\cdot y_{i}$\\
  \hline
  Description & 
                The dot product is an operation between two vectors of the same size. In our equation $n$ is the shared dimension of vectors $\vv{\bm{x}}$ and $\vv{\bm{y}}.$ The dot product is computed where each corresponding scalar entry from each vector is multiplied together and summed for all entries.
  \\
  \hline
  Sources& \citep{strang09} \\
  \hline
  Ref.\ By & IM\ref{im:linesearch},IM\ref{im:CGsearchdirection},IM\ref{im:QNsearchdirection}\\
  \hline
\end{tabular}
\end{minipage}\\
\\

\noindent
\begin{minipage}{\textwidth}
\renewcommand*{\arraystretch}{1.5}
\begin{tabular}{| p{\colAwidth} | p{\colBwidth}|}
\hline
\rowcolor[gray]{0.9}
Number& DD\refstepcounter{datadefnum}\thedatadefnum \label{dd:Transpose}\\
\hline
Label& \bf Transpose\\
\hline
Symbol &$\vv{\bm{x}}^T, \mathbf{A}^T$ \\
\hline
% Units& $Mt^{-3}$\\
% \hline
  SI Units & -\\
  \hline
  Equation&$[\mathbf{A}^T]_{i,j} = [\mathbf{A}]_{j,i}$\\
  \hline
  Description & 
                The transpose of a matrix (or vector) results in another matrix where the element of the $j$th row and $i$th column is the element of the $i$th row and $j$th column of the original matrix.
  \\
  \hline
  Sources& \citep{strang09} \\
  \hline
  Ref.\ By & IM\ref{im:CGsearchdirection},IM\ref{im:QNsearchdirection}\\
  \hline
\end{tabular}
\end{minipage}\\
\\

\noindent
\begin{minipage}{\textwidth}
\renewcommand*{\arraystretch}{1.5}
\begin{tabular}{| p{\colAwidth} | p{\colBwidth}|}
\hline
\rowcolor[gray]{0.9}
Number& DD\refstepcounter{datadefnum}\thedatadefnum \label{dd:Gradient}\\
\hline
Label& \bf Gradient\\
\hline
Symbol &$\nabla f$ \\
\hline
% Units& $Mt^{-3}$\\
% \hline
  SI Units & -\\
  \hline
  Equation&$\nabla f = [\frac{\partial f}{\partial x_1},\frac{\partial f}{\partial x_2},...,\frac{\partial f}{\partial x_n}]$\\
  \hline
  Description & 
                The gradient of a scalar function is a $n$-dimensional vector. Each component of the gradient is the partial derivative of the scalar function with respect to the corresponding one of the $n$ components.
  \\
  \hline
  Sources& \citep{strang09} \\
  \hline
  Ref.\ By & IM\ref{im:linesearch},IM\ref{im:CGsearchdirection},IM\ref{im:QNsearchdirection}\\
  \hline
\end{tabular}
\end{minipage}\\
\\

\noindent
\begin{minipage}{\textwidth}
\renewcommand*{\arraystretch}{1.5}
\begin{tabular}{| p{\colAwidth} | p{\colBwidth}|}
\hline
\rowcolor[gray]{0.9}
Number& DD\refstepcounter{datadefnum}\thedatadefnum \label{dd:Hessian}\\
\hline
Label& \bf Hessian\\
\hline
Symbol &$\mathbf{H}_f$ \\
\hline
% Units& $Mt^{-3}$\\
% \hline
  SI Units & -\\
  \hline
  Equation&$[\mathbf{H}_f]_{i,j} = \frac{\partial^2 f}{\partial x_i \partial x_j}$\\
  \hline
  Description & 
                The Hessian is a square $n \times n$ matrix, which contains second order partial derivatives of the function $f$. Each $(i,j)$th entry is given as the second order partial with respect to the $i$th and $j$th component. 
  \\
  \hline
  Sources& \citep{strang09} \\
  \hline
  Ref.\ By & IM\ref{im:QNsearchdirection}\\
  \hline
\end{tabular}
\end{minipage}\\
\\


\subsubsection{Instance Models} \label{sec_instance}    

This section takes the prior sections' abstractions and generates instance models. This builds off of prior data definitions, assumptions, theoretical models to present a high level view of how to specifically tackle the problem of function minimization.

~\newline

%Instance Model 1

\noindent
\begin{minipage}{\textwidth}
\renewcommand*{\arraystretch}{1.5}
\begin{tabular}{| p{\colAwidth} | p{\colBwidth}|}
  \hline
  \rowcolor[gray]{0.9}
  Number& IM\refstepcounter{instnum}\theinstnum \label{im:linesearch}\\
  \hline
  Label& \bf Multi-Dimensional Line Search\\
  \hline
  Input&$\vv{\bm{x}}_{0}$, 
  $\epsilon$, $f$, $\text{max}_{\text{steps}}$ \\
  & The input is constrained so that $f$ can be in the quadratic form (A\ref{assumption:quadratic}) and so that $\vv{\bm{x}}_{0}$ is of the proper dimension (A\ref{assumption:maxdim})\\
  \hline
  Output&$\vv{\bm{x}}_{k+1}$, such that\\
  &$|| \nabla f(\vv{\bm{x}}_{k+1})|| \leq \epsilon$ (A\ref{assumption:convexity}) or  $\text{max}_{\text{steps}} > k+1$ \\
  \hline
  Equation&$\vv{\bm{x}}_{k+1} = \vv{\bm{x}}_{k} + \alpha_{k}\vv{\bm{s}}_{k} $, \\
  &$\vv{\bm{x}}_{k+1}$ next iteration
  \\
  \hline
  Description&$\alpha_{k}$ is the step-size computed through a sub-routine\\
  &$\vv{\bm{x}}_{k+1}$ is the $k+1$-th iteration of our potential minimum .\\
  &$\vv{\bm{s}}_{k}$ is the search direction computed through a sub-routine\\
  &$\epsilon$ is a tolerance parameter (0 implies global minimum is reached for convex functions).\\
  &$\text{max}_{\text{steps}}$ is a constant term that dictates the maximum number of steps the algorithm can run for. This keeps the problem computationally feasible for test cases that are convex but may require too many steps.
  \\
  \hline
  Sources& \citep{Boyd2005ConvexO} \\
  \hline
\end{tabular}
\end{minipage}\\
\\

%~\newline

%Instance Model 2

\noindent
\begin{minipage}{\textwidth}
\renewcommand*{\arraystretch}{1.5}
\begin{tabular}{| p{\colAwidth} | p{\colBwidth}|}
  \hline
  \rowcolor[gray]{0.9}
  Number& IM\refstepcounter{instnum}\theinstnum \label{im:CGsearchdirection}\\
  \hline
  Label& \bf Conjugate-Gradient search direction\\
  \hline
  Input&$\vv{\bm{x}}_{k}:$ $\in \mathbb{R}^n$, \\ 
  & $\vv{\bm{x}}_{k-1}:$ $\in \mathbb{R}^n$, \\ & $\vv{\bm{s}}_{k-1}:$ $\in \mathbb{R}^n$ \\
  \\
  \hline
  Output&$\vv{\bm{s}}_{k}:$ $\in \mathbb{R}^n$  \\
  &the $k$th iteration's search direction
  \\
  \hline
  Description&$\vv{\bm{x}}_{k}$ is the $(k)$-th iteration of our potential minimum .\\
  &$\vv{\bm{x}}_{k-1}$ is the $(k-1)$-th iteration of our potential minimum .\\
  &$\vv{\bm{s}}_{k-1}$ is the search direction for the $(k-1)$th iteration.
  \\
  \hline
  Sources& \citep{Boyd2005ConvexO} \\
  \hline
  Ref.\ By & IM\ref{im:linesearch}\\
  \hline
\end{tabular}
\end{minipage}\\
\\

%~\newline

%Instance Model 3

\noindent
\begin{minipage}{\textwidth}
\renewcommand*{\arraystretch}{1.5}
\begin{tabular}{| p{\colAwidth} | p{\colBwidth}|}
  \hline
  \rowcolor[gray]{0.9}
  Number& IM\refstepcounter{instnum}\theinstnum \label{im:QNsearchdirection}\\
  \hline
  Label& \bf Quasi-Newton search direction\\
  \hline
  Input&$\vv{\bm{x}}_{k}:$ $\in \mathbb{R}^n$, \\ 
  & $\vv{\bm{x}}_{k-1}:$ $\in \mathbb{R}^n$, \\ & $\vv{\bm{s}}_{k-1}:$ $\in \mathbb{R}^n$ \\ & $\bm{H}_{k-1}:$ $\in \mathbb{R}^{n\times n}$ \\
  \\
  \hline
  Output&$\vv{\bm{s}}_{k}:$ $\in \mathbb{R}^n$  \\
  &the $k$th iteration's search direction
  \\
  \hline
  Description&$\vv{\bm{x}}_{k}$ is the $(k)$-th iteration of our potential minimum .\\
  &$\vv{\bm{x}}_{k-1}$ is the $(k-1)$-th iteration of our potential minimum .\\
  &$\vv{\bm{s}}_{k-1}$ is the search direction for the $(k-1)$th iteration.
  \\
  & $\bm{H}_{k-1}$ is the approximation to the current Hessian used to compute the search direction
  \\
  \hline
  Sources& \citep{Boyd2005ConvexO} \\
  \hline
  Ref.\ By & IM\ref{im:linesearch}\\
  \hline
\end{tabular}
\end{minipage}\\
\\

%~\newline


\subsubsection{Input Data Constraints} \label{sec_DataConstraints}    

The vectors inputted into the minimizer should not exceed $\max_{\text{dim}}$ specified by the developer. This is to keep the problem feasible. The input function should also be convex, this is to guarantee convergence to a global minimum.


\section{Requirements}

\plt{The requirements refine the goal statement.  They will make heavy use of
  references to the instance models.}

This section provides the functional requirements, the business tasks that the
software is expected to complete, and the nonfunctional requirements, the
qualities that the software is expected to exhibit.

\newpage
\subsection{Functional Requirements}

\noindent 
\begin{itemize}

\item[R\refstepcounter{reqnum}\thereqnum \label{r:maxdim}:] The function and input vector are in the specified dimension which does not exceed maximum defined dimension.

\item[R\refstepcounter{reqnum}\thereqnum \label{r:quadratic}:] The function provided can be expressed in quadratic form. 

\item[R\refstepcounter{reqnum}\thereqnum \label{R_Calculate}:] \plt{Calculation
    related requirements.}

\item[R\refstepcounter{reqnum}\thereqnum \label{R_VerifyOutput}:]
  \plt{Verification related requirements.}

\item[R\refstepcounter{reqnum}\thereqnum \label{R_Output}:] \plt{Output related
    requirements.}

\end{itemize}

\plt{Every IM should map to at least one requirement, but not every requirement
  has to map to a corresponding IM.}

\subsection{Nonfunctional Requirements}

Listed here are the nonfunctional requirements for the optimization library.

\noindent \begin{itemize}

\item[NFR\refstepcounter{nfrnum}\thenfrnum \label{NFR_Accuracy}:]
  \textbf{Accuracy} The accuracy of the output should be within the provided accuracy parameter provided. This should meet the level required for scientific and engineering applications. 
\item[NFR\refstepcounter{nfrnum}\thenfrnum \label{NFR_Usability}:] \textbf{Usability}
  The software should be usable via interfacing with the program library. See the User Characteristics section for what is expected when interfacing with said library. 

\item[NFR\refstepcounter{nfrnum}\thenfrnum \label{NFR_Maintainability}:]
  \textbf{Maintainability} The effort required to make any of the likely
    changes listed for Optimization Library should be less than $t_{\text{main}}$ of the original
    development time. $t_{\text{main}}$ is then a symbolic constant that can be found at the end of the report.

\item[NFR\refstepcounter{nfrnum}\thenfrnum \label{NFR_Portability}:]
  \textbf{Portability} This library should be able to run on any system that can host an operating system and conduct computations from standard programming libraries.

\item[NFR\refstepcounter{nfrnum}\thenfrnum \label{NFR_Interpretability}:]
  \textbf{Interpretability} The library should be easily readable to domain experts.

\end{itemize}



\section{Likely Changes}    

\noindent \begin{itemize}

\item[LC\refstepcounter{lcnum}\thelcnum\label{LC_likely1}:] Potentially downsize number of minimizers in the family. 

\end{itemize}

\section{Unlikely Changes}    

\noindent \begin{itemize}

\item[LC\refstepcounter{lcnum}\thelcnum\label{LC_unlikely1}:] will contain both Conjugate-Gradient and Quasi-Newton methods.

\end{itemize}

\section{Traceability Matrices and Graphs}

The purpose of the traceability matrices is to provide easy references on what
has to be additionally modified if a certain component is changed.  Every time a
component is changed, the items in the column of that component that are marked
with an ``X'' may have to be modified as well.  Table~\ref{Table:trace} shows the
dependencies of theoretical models, general definitions, data definitions, and
instance models with each other. Table~\ref{Table:R_trace} shows the
dependencies of instance models, requirements, and data constraints on each
other. Table~\ref{Table:A_trace} shows the dependencies of theoretical models,
general definitions, data definitions, instance models, and likely changes on
the assumptions.

\plt{You will have to modify these tables for your problem.}

\plt{The traceability matrix is not generally symmetric.  If GD1 uses A1, that
  means that GD1's derivation or presentation requires invocation of A1.  A1
  does not use GD1.  A1 is ``used by'' GD1.}

\plt{The traceability matrix is challenging to maintain manually.  Please do
  your best.  In the future tools (like Drasil) will make this much easier.}

\afterpage{
\begin{landscape}
\begin{table}[h!]
\centering
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|}
\hline
	& A\ref{assumption:convexity}& A\ref{assumption:quadratic}& A\ref{assumption:maxdim} \\
\hline
TM:CON        & X& &  \\ \hline
GD\ref{gd:funcmin}           &X & X&X  \\ \hline
DD\ref{dd:DotProd}         & & & X \\ \hline
DD\ref{dd:Transpose}    & & &X  \\ \hline
DD\ref{dd:Gradient}     & & &X  \\ \hline
DD\ref{dd:Hessian}       & &X & \\ \hline
IM\ref{im:linesearch}        &X &X &X  \\ \hline
IM\ref{im:CGsearchdirection}         &X &X &X \\ \hline
IM\ref{im:QNsearchdirection}         & X&X &X \\ \hline
LC\ref{LC_likely1}       & & & \\ \hline
LC\ref{LC_unlikely1}       & & & \\
\hline
\end{tabular}
\caption{Traceability Matrix Showing the Connections Between Assumptions and Other Items}
\label{Table:A_trace}
\end{table}
\end{landscape}
}

\begin{table}[h!]
\centering
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|}
\hline        
	& TM:CON& DD\ref{dd:DotProd} & DD\ref{dd:Transpose} & DD\ref{dd:Gradient}& DD\ref{dd:Hessian} & IM\ref{im:linesearch}& IM\ref{im:CGsearchdirection}& IM\ref{im:QNsearchdirection}\\
\hline
TM:CON                    &X & & & & & & &  \\ \hline
GD\ref{gd:funcmin}        &X & & & & & & &  \\ \hline
DD\ref{dd:DotProd}      & &X & & & & & &  \\ \hline
DD\ref{dd:Transpose} & & &X & & & & &  \\ \hline
DD\ref{dd:Gradient}  & & & &X & & & &  \\ \hline
DD\ref{dd:Hessian}    & & & & & X& & &  \\ \hline
IM\ref{im:linesearch}     & &X &X &X & &X & &  \\ \hline
IM\ref{im:CGsearchdirection}      & &X &X &X & & & X&  \\ \hline
IM\ref{im:QNsearchdirection}      & &X &X &X &X & & &X  \\ \hline

\end{tabular}
\caption{Traceability Matrix Showing the Connections Between Items of Different Sections}
\label{Table:trace}
\end{table}

\begin{table}[h!]
\centering
\begin{tabular}{|c|c|c|c|c|c|c|c|}
\hline
	& IM\ref{im:linesearch}& IM\ref{im:CGsearchdirection}& IM\ref{im:QNsearchdirection}& R\ref{r:maxdim}& R\ref{r:quadratic} \\
\hline
IM\ref{im:linesearch}            &X &X &X &X &X  \\ \hline
IM\ref{im:CGsearchdirection}            & & X& & X&  \\ \hline
IM\ref{im:QNsearchdirection}          & & & X& X&  \\ \hline
R\ref{r:maxdim}          & & & &X &  \\ \hline
R\ref{r:quadratic}     & & & & & X \\ \hline
\end{tabular}
\caption{Traceability Matrix Showing the Connections Between Requirements and Instance Models}
\label{Table:R_trace}
\end{table}



% \begin{figure}[h!]
% 	\begin{center}
% 		%\rotatebox{-90}
% 		{
% 			\includegraphics[width=\textwidth]{ATrace.png}
% 		}
% 		\caption{\label{Fig_ATrace} Traceability Matrix Showing the Connections Between Items of Different Sections}
% 	\end{center}
% \end{figure}


% \begin{figure}[h!]
% 	\begin{center}
% 		%\rotatebox{-90}
% 		{
% 			\includegraphics[width=0.7\textwidth]{RTrace.png}
% 		}
% 		\caption{\label{Fig_RTrace} Traceability Matrix Showing the Connections Between Requirements, Instance Models, and Data Constraints}
% 	\end{center}
% \end{figure}


\section{Values of Auxiliary Constants}

$t_{\text{main}} = 0.1$
\\
$\max_{\text{dim}} = 6$

\newpage

\bibliographystyle {plainnat}
%\bibliography {../../refs/References}




\bibliography{SRS}

\end{document}